<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8" />
      <meta
         name="viewport"
         content="width=device-width,initial-scale=1"
      />
      <title>Live Voice → OpenAI Realtime</title>
      <style>
         body {
            font-family: Arial, sans-serif;
            max-width: 700px;
            margin: 20px auto;
            padding: 10px;
         }
         button {
            padding: 8px 14px;
            margin-right: 8px;
         }
         #status {
            font-weight: 600;
            margin-left: 12px;
         }
         .status-on {
            color: green;
         }
         .status-off {
            color: #b00;
         }
         #partial {
            color: blue;
            font-weight: bold;
            min-height: 24px;
         }
         #final {
            margin-top: 12px;
            border: 1px solid #eee;
            padding: 12px;
            min-height: 160px;
            background: #fafafa;
            white-space: pre-wrap;
         }
         #log {
            margin-top: 10px;
            font-size: 12px;
            max-height: 120px;
            overflow: auto;
            border: 1px solid #f0f0f0;
            padding: 8px;
            background: #fff;
         }
      </style>
   </head>
   <body>
      <h2>Live Voice → Realtime Transcription Test</h2>

      <p>
         WebSocket:
         <input
            id="wsUrl"
            style="width: 360px"
            value="ws://localhost:8080/ws"
         />
         <button id="connectBtn">Connect</button>
         <span
            id="status"
            class="status-off"
            >Disconnected</span
         >
      </p>

      <p>
         <button
            id="startBtn"
            disabled
         >
            Start Mic
         </button>
         <button
            id="stopBtn"
            disabled
         >
            Stop Mic
         </button>
         <button
            id="closeBtn"
            disabled
         >
            Close WS
         </button>
      </p>

      <div>
         <div id="partial">Partial transcript...</div>
         <div id="final"></div>
      </div>

      <div id="log"></div>

      <script>
         (async function () {
            const connectBtn = document.getElementById("connectBtn");
            const startBtn = document.getElementById("startBtn");
            const stopBtn = document.getElementById("stopBtn");
            const closeBtn = document.getElementById("closeBtn");
            const statusEl = document.getElementById("status");
            const partialEl = document.getElementById("partial");
            const finalEl = document.getElementById("final");
            const logEl = document.getElementById("log");
            const wsUrlInput = document.getElementById("wsUrl");

            let ws = null;
            let audioContext = null;
            let processor = null;
            let stream = null;
            let sending = false;

            function log(...args) {
               console.log(...args);
               logEl.textContent +=
                  args
                     .map((a) =>
                        typeof a === "string" ? a : JSON.stringify(a)
                     )
                     .join(" ") + "\n";
               logEl.scrollTop = logEl.scrollHeight;
            }

            function setStatus(connected) {
               statusEl.textContent = connected ? "Connected" : "Disconnected";
               statusEl.className = connected ? "status-on" : "status-off";
               startBtn.disabled = !connected;
               closeBtn.disabled = !connected;
            }

            connectBtn.onclick = () => {
               if (ws && ws.readyState === WebSocket.OPEN) return;
               ws = new WebSocket(wsUrlInput.value);
               ws.binaryType = "arraybuffer";

               ws.onopen = () => {
                  log("WS open");
                  setStatus(true);
                  // Start control message for your backend
                  ws.send(
                     JSON.stringify({
                        type: "start",
                        model: "gpt-4o-realtime-preview",
                        audio: true,
                        transcript: true,
                     })
                  );
                  startBtn.disabled = false;
                  stopBtn.disabled = true;
                  closeBtn.disabled = false;
               };

               ws.onmessage = (evt) => {
                  const data = evt.data;
                  try {
                     const str =
                        typeof data === "string"
                           ? data
                           : new TextDecoder().decode(data);
                     let obj = null;
                     try {
                        obj = JSON.parse(str);
                     } catch (e) {}
                     if (obj?.type === "transcript.delta")
                        partialEl.textContent = obj.delta;
                     else if (obj?.type === "transcript.final") {
                        finalEl.textContent += obj.transcript + "\n";
                        partialEl.textContent = "";
                     } else log("MSG(JSON):", obj);
                  } catch (err) {
                     log("parse error", err);
                  }
               };

               ws.onerror = (e) => log("WS error", e);
               ws.onclose = (e) => {
                  log("WS closed", e.code, e.reason);
                  setStatus(false);
                  startBtn.disabled = true;
                  stopBtn.disabled = true;
                  closeBtn.disabled = true;
               };
            };

            function floatTo16BitPCM(float32Array) {
               const buffer = new ArrayBuffer(float32Array.length * 2);
               const view = new DataView(buffer);
               let offset = 0;
               for (let i = 0; i < float32Array.length; i++, offset += 2) {
                  let s = Math.max(-1, Math.min(1, float32Array[i]));
                  view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
               }
               return buffer;
            }

            function encodeBase64(buffer) {
               let binary = "";
               const bytes = new Uint8Array(buffer);
               const chunkSize = 0x8000;
               for (let i = 0; i < bytes.length; i += chunkSize) {
                  let sub = bytes.subarray(i, i + chunkSize);
                  binary += String.fromCharCode.apply(null, sub);
               }
               return btoa(binary);
            }

            async function startMic() {
               if (!ws || ws.readyState !== WebSocket.OPEN) {
                  alert("Connect WS first");
                  return;
               }

               stream = await navigator.mediaDevices.getUserMedia({
                  audio: true,
               });
               audioContext = new AudioContext({ sampleRate: 24000 });
               const source = audioContext.createMediaStreamSource(stream);
               processor = audioContext.createScriptProcessor(4096, 1, 1);
               source.connect(processor);
               processor.connect(audioContext.destination);

               processor.onaudioprocess = (e) => {
                  if (!sending) return;
                  const input = e.inputBuffer.getChannelData(0);
                  const pcm = floatTo16BitPCM(input);
                  const base64 = encodeBase64(pcm);
                  try {
                     ws.send(
                        JSON.stringify({
                           type: "input_audio_buffer.append",
                           audio: base64,
                        })
                     );
                  } catch (err) {
                     log("send error", err);
                  }
               };

               sending = true;
               startBtn.disabled = true;
               stopBtn.disabled = false;
               log("Mic streaming started");
            }

            async function stopMic() {
               sending = false;
               if (processor) {
                  processor.disconnect();
                  processor = null;
               }
               if (audioContext) {
                  audioContext.close();
                  audioContext = null;
               }
               if (stream) {
                  stream.getTracks().forEach((t) => t.stop());
                  stream = null;
               }
               try {
                  ws.send(
                     JSON.stringify({ type: "input_audio_buffer.commit" })
                  );
               } catch (e) {}
               startBtn.disabled = false;
               stopBtn.disabled = true;
               log("Mic streaming stopped");
            }

            startBtn.onclick = startMic;
            stopBtn.onclick = stopMic;
            closeBtn.onclick = () => {
               if (ws) {
                  ws.close();
                  ws = null;
                  setStatus(false);
               }
            };

            window.addEventListener("beforeunload", stopMic);
         })();
      </script>
   </body>
</html>
